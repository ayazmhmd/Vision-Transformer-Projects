{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3115,"status":"ok","timestamp":1673947909606,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"45hRZuZc0JyK","outputId":"869e1170-fe83-4742-a4e1-1df2fd80bcee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"45hRZuZc0JyK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Dos492BwEUA"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Fashion_mnist')"],"id":"0Dos492BwEUA"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3256,"status":"ok","timestamp":1673947912857,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"y7Zjzkdptx6R","outputId":"55d390e6-b915-4387-c854-3b349e40969e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: vit-pytorch in /usr/local/lib/python3.8/dist-packages (0.40.2)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.8/dist-packages (from vit-pytorch) (1.13.0+cu116)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from vit-pytorch) (0.6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from vit-pytorch) (0.14.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10->vit-pytorch) (4.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->vit-pytorch) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->vit-pytorch) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->vit-pytorch) (2.25.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->vit-pytorch) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->vit-pytorch) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->vit-pytorch) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->vit-pytorch) (2.10)\n"]}],"source":["!pip install vit-pytorch"],"id":"y7Zjzkdptx6R"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673947912857,"user":{"displayName":"colab 123","userId":"15461834718315349574"},"user_tz":-300},"id":"RDDHPTS9Hfqi","outputId":"c83d9e13-ae6b-4d8a-c9ba-5e2997995d85"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fccecf425b0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","from tqdm import tqdm, trange\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","\n","from torchvision.transforms import ToTensor\n","from torchvision.datasets.mnist import MNIST\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","\n"],"id":"RDDHPTS9Hfqi"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBqwyBqjHxnt"},"outputs":[],"source":["def patchify(images, n_patches):\n","    n, c, h, w = images.shape\n","\n","    assert h == w, \"Patchify method is implemented for square images only\"\n","\n","    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n","    patch_size = h // n_patches\n","\n","    for idx, image in enumerate(images):\n","        for i in range(n_patches):\n","            for j in range(n_patches):\n","                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n","                patches[idx, i * n_patches + j] = patch.flatten()\n","    return patches\n","\n"],"id":"HBqwyBqjHxnt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHx2D3vBH1uK"},"outputs":[],"source":["class MyMSA(nn.Module):\n","    def __init__(self, d, n_heads=2):\n","        super(MyMSA, self).__init__()\n","        self.d = d\n","        self.n_heads = n_heads\n","\n","        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n","\n","        d_head = int(d / n_heads)\n","        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n","        self.d_head = d_head\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, sequences):\n","        # Sequences has shape (N, seq_length, token_dim)\n","        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n","        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n","        result = []\n","        for sequence in sequences:\n","            seq_result = []\n","            for head in range(self.n_heads):\n","                q_mapping = self.q_mappings[head]\n","                k_mapping = self.k_mappings[head]\n","                v_mapping = self.v_mappings[head]\n","\n","                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n","                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n","\n","                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n","                seq_result.append(attention @ v)\n","            result.append(torch.hstack(seq_result))\n","        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n","\n"],"id":"cHx2D3vBH1uK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgji5QxXH3rp"},"outputs":[],"source":["class MyViTBlock(nn.Module):\n","    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n","        super(MyViTBlock, self).__init__()\n","        self.hidden_d = hidden_d\n","        self.n_heads = n_heads\n","\n","        self.norm1 = nn.LayerNorm(hidden_d)\n","        self.mhsa = MyMSA(hidden_d, n_heads)\n","        self.norm2 = nn.LayerNorm(hidden_d)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n","            nn.GELU(),\n","            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n","        )\n","\n","    def forward(self, x):\n","        out = x + self.mhsa(self.norm1(x))\n","        out = out + self.mlp(self.norm2(out))\n","        return out\n","\n","class MyViT(nn.Module):\n","    def __init__(self, chw, n_patches=12, n_blocks=2, hidden_d=8, n_heads=4, out_d=10):\n","        # Super constructor\n","        super(MyViT, self).__init__()\n","        \n","        # Attributes\n","        self.chw = chw # ( C , H , W )\n","        self.n_patches = n_patches\n","        self.n_blocks = n_blocks\n","        self.n_heads = n_heads\n","        self.hidden_d = hidden_d\n","        \n","        # Input and patches sizes\n","        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n","        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n","        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n","\n","        # 1) Linear mapper\n","        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n","        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n","        \n","        # 2) Learnable classification token\n","        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n","        \n","        # 3) Positional embedding\n","        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)\n","        \n","        # 4) Transformer encoder blocks\n","        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n","        \n","        # 5) Classification MLPk\n","        self.mlp = nn.Sequential(\n","            nn.Linear(self.hidden_d, out_d),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","    def forward(self, images):\n","        # Dividing images into patches\n","        n, c, h, w = images.shape\n","        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)\n","        \n","        # Running linear layer tokenization\n","        # Map the vector corresponding to each patch to the hidden size dimension\n","        tokens = self.linear_mapper(patches)\n","        \n","        # Adding classification token to the tokens\n","        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)\n","        \n","        # Adding positional embedding\n","        out = tokens + self.positional_embeddings.repeat(n, 1, 1)\n","        \n","        # Transformer Blocks\n","        for block in self.blocks:\n","            out = block(out)\n","            \n","        # Getting the classification token only\n","        out = out[:, 0]\n","        \n","        return self.mlp(out) # Map to output dimension, output category distribution\n","    \n","\n"],"id":"qgji5QxXH3rp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsiVzr-3H9UD"},"outputs":[],"source":["def get_positional_embeddings(sequence_length, d):\n","    result = torch.ones(sequence_length, d)\n","    for i in range(sequence_length):\n","        for j in range(d):\n","            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n","    return result\n"],"id":"QsiVzr-3H9UD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5yT2mkg0Hft6","outputId":"1ba0d065-f01f-499b-d841-52b75cd1fa3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device:  cpu \n","training Start\n","\n","[    0/60000 (  0%)]  Loss: 2.3000\n","[10000/60000 ( 17%)]  Loss: 2.2918\n","[20000/60000 ( 33%)]  Loss: 2.1529\n","[30000/60000 ( 50%)]  Loss: 2.0649\n","[40000/60000 ( 67%)]  Loss: 1.9784\n","[50000/60000 ( 83%)]  Loss: 1.8849\n","Epoch 1/15 loss: 2.06\n","Test loss: 1.82\n","Test accuracy: 64.99%\n","[    0/60000 (  0%)]  Loss: 1.8416\n","[10000/60000 ( 17%)]  Loss: 1.7931\n","[20000/60000 ( 33%)]  Loss: 1.6554\n","[30000/60000 ( 50%)]  Loss: 1.7059\n","[40000/60000 ( 67%)]  Loss: 1.6359\n","[50000/60000 ( 83%)]  Loss: 1.5967\n","Epoch 2/15 loss: 1.71\n","Test loss: 1.60\n","Test accuracy: 86.58%\n","[    0/60000 (  0%)]  Loss: 1.6329\n","[10000/60000 ( 17%)]  Loss: 1.6136\n","[20000/60000 ( 33%)]  Loss: 1.5965\n","[30000/60000 ( 50%)]  Loss: 1.5221\n","[40000/60000 ( 67%)]  Loss: 1.6447\n","[50000/60000 ( 83%)]  Loss: 1.5488\n","Epoch 3/15 loss: 1.59\n","Test loss: 1.56\n","Test accuracy: 89.94%\n","[    0/60000 (  0%)]  Loss: 1.5677\n","[10000/60000 ( 17%)]  Loss: 1.5711\n","[20000/60000 ( 33%)]  Loss: 1.5331\n","[30000/60000 ( 50%)]  Loss: 1.6180\n","[40000/60000 ( 67%)]  Loss: 1.6295\n","[50000/60000 ( 83%)]  Loss: 1.5623\n","Epoch 4/15 loss: 1.56\n","Test loss: 1.56\n","Test accuracy: 90.26%\n","[    0/60000 (  0%)]  Loss: 1.5543\n","[10000/60000 ( 17%)]  Loss: 1.5400\n","[20000/60000 ( 33%)]  Loss: 1.5663\n"]}],"source":["# Loading data\n","transform = ToTensor()\n","\n","train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n","test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_set, shuffle=True, batch_size=100)\n","test_loader = DataLoader(test_set, shuffle=False, batch_size=100)\n","\n","# Defining model and training options\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n","model = MyViT((1, 28, 28), n_patches=14, n_blocks=8, hidden_d=28, n_heads=4, out_d=10).to(device)\n","N_EPOCHS = 15\n","LR = 0.001\n","\n","# Training loop\n","optimizer = Adam(model.parameters(), lr=LR)\n","criterion = CrossEntropyLoss()\n","print(\"training Start\\n\")\n","for epoch in range(0,N_EPOCHS):\n","    train_loss = 0.0\n","     \n","    for step, (x, y) in enumerate(train_loader):\n","        # print('ayaz')\n","        # x, y = batch\n","        # print('b')\n","        x, y = x.to(device), y.to(device)\n","        y_hat = model(x)\n","        loss = criterion(y_hat, y)\n","\n","        train_loss += loss.detach().cpu().item() / len(train_loader)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if step % 100 == 0:\n","          print('[' +  '{:5}'.format(step * len(x)) + '/' + '{:5}'.format(len(train_loader.dataset)) +\n","                ' (' + '{:3.0f}'.format(100 * step / len(train_loader)) + '%)]  Loss: ' +\n","                '{:6.4f}'.format(loss.item()))\n","\n","    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n","\n","# # Test loop\n","# with torch.no_grad():\n","    correct, total = 0, 0\n","    test_loss = 0.0\n","    for step, (x, y) in enumerate(test_loader):\n","        x, y = x.to(device), y.to(device)\n","        y_hat = model(x)\n","        loss = criterion(y_hat, y)\n","        test_loss += loss.detach().cpu().item() / len(test_loader)\n","\n","        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n","        total += len(x)\n","    print(f\"Test loss: {test_loss:.2f}\")\n","    print(f\"Test accuracy: {correct / total * 100:.2f}%\")"],"id":"5yT2mkg0Hft6"}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}